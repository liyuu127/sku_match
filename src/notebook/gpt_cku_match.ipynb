{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import re\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "# ========== Step 1. 基础信息提取 ==========\n",
    "brand_dict = [\"康师傅\", \"汤达人\", \"上好佳\", \"海氏海诺\", \"爱斐堡\", \"统一\", \"金龙鱼\", \"旺旺\", \"农夫山泉\"]\n",
    "\n",
    "def extract_brand(name):\n",
    "    for b in brand_dict:\n",
    "        if b in name:\n",
    "            return b\n",
    "    return \"\"\n",
    "\n",
    "def extract_spec(name):\n",
    "    m = re.findall(r'[\\d\\.]+[gG克斤mMlL升包袋盒瓶罐卷片只]*', name)\n",
    "    return m[0] if m else \"\"\n",
    "\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^0-9a-zA-Z\\u4e00-\\u9fa5]', '', text)\n",
    "\n",
    "def parse_product_info(name):\n",
    "    brand = extract_brand(name)\n",
    "    spec = extract_spec(name)\n",
    "    core = clean_text(name.replace(brand, '').replace(spec, ''))\n",
    "    return brand, spec, core\n",
    "\n",
    "# ========== Step 2. 相似度计算 ==========\n",
    "def calc_similarity(m, e):\n",
    "    # 条码完全相同则满分\n",
    "    if str(m['upc码']) == str(e['条码']) and str(m['upc码']).strip():\n",
    "        return 1.0\n",
    "\n",
    "    brand_sim = 1.0 if m['品牌'] == e['品牌'] and m['品牌'] else (\n",
    "        0.8 if m['品牌'] in e['品牌'] or e['品牌'] in m['品牌'] else 0.0\n",
    "    )\n",
    "    name_sim = fuzz.token_set_ratio(m['核心名'], e['核心名']) / 100\n",
    "    spec_sim = fuzz.ratio(m['规格'], e['规格']) / 100\n",
    "\n",
    "    return 0.5 * name_sim + 0.3 * spec_sim + 0.2 * brand_sim\n",
    "\n",
    "# ========== Step 3. 主流程 ==========\n",
    "def match_sku(meituan_path, elme_path, output_path):\n",
    "    mt = pd.read_csv(meituan_path)\n",
    "    el = pd.read_csv(elme_path)\n",
    "\n",
    "    # 解析信息\n",
    "    for df, col_name in [(mt, '商品名称'), (el, '商品名称')]:\n",
    "        parsed = df[col_name].apply(parse_product_info)\n",
    "        df['品牌'] = parsed.map(lambda x: x[0])\n",
    "        df['规格'] = parsed.map(lambda x: x[1])\n",
    "        df['核心名'] = parsed.map(lambda x: x[2])\n",
    "\n",
    "    result_rows = []\n",
    "    for _, mrow in mt.iterrows():\n",
    "        candidates = []\n",
    "        for _, erow in el.iterrows():\n",
    "            score = calc_similarity(mrow, erow)\n",
    "            candidates.append((erow['商品id'], erow['商品名称'], score))\n",
    "        top3 = sorted(candidates, key=lambda x: x[2], reverse=True)[:3]\n",
    "\n",
    "        result_rows.append({\n",
    "            \"美团商品ID\": mrow[\"商品ID\"],\n",
    "            \"美团名称\": mrow[\"商品名称\"],\n",
    "            \"饿了么Top1_ID\": top3[0][0],\n",
    "            \"饿了么Top1_名称\": top3[0][1],\n",
    "            \"相似度1\": round(top3[0][2], 3),\n",
    "            \"饿了么Top2_ID\": top3[1][0] if len(top3) > 1 else \"\",\n",
    "            \"饿了么Top2_名称\": top3[1][1] if len(top3) > 1 else \"\",\n",
    "            \"相似度2\": round(top3[1][2], 3) if len(top3) > 1 else \"\",\n",
    "            \"饿了么Top3_ID\": top3[2][0] if len(top3) > 2 else \"\",\n",
    "            \"饿了么Top3_名称\": top3[2][1] if len(top3) > 2 else \"\",\n",
    "            \"相似度3\": round(top3[2][2], 3) if len(top3) > 2 else \"\",\n",
    "        })\n",
    "\n",
    "    pd.DataFrame(result_rows).to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"✅ 匹配完成，结果已保存到: {output_path}\")\n",
    "\n",
    "# 示例运行\n",
    "match_sku(\"meituan_sku.csv\", \"elme_sku_small.csv\", \"sku_match_result.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
